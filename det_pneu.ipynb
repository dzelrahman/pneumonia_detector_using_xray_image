{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "det_pneu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JAwkgJZ_749",
        "colab_type": "text"
      },
      "source": [
        "# Deteksi Pneumonia\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDTkq4sY9oed",
        "colab_type": "text"
      },
      "source": [
        "Layanan kesehatan / kesehatan adalah bagian penting dari revolusi teknologi, dengan banyaknya teknik deep learning yang diaplikasikan pada banyak masalah-masalah medis saat ini. \n",
        "\n",
        "Data yang digunakan adalah citra x-ray yang akan dimasukkan ke dalam model untuk menentukan apakah seseorang mengidap pneumonia ataukah tidak. Model ini merupakan model klasifikasi binari, yang akan menghasilkan dua hasil prediksi, ya ataukah tidak (0 atau 1).\n",
        "\n",
        "Notebook ini dibuat menggunakan paltform google colab, dan menggunakan transfer learning dari arsitektur ResNet50. Setelah training selama dan sepanjang 10 epochs, dicapai akurasi sebesar lebih dari 80%. Modifikasi kecil dan perubahan/penambahan komponen arsitektur tentu saja dapat meningkatkan akurasi hingga mencapai 90% atau bahkan lebih dari itu.\n",
        "\n",
        "Dengan menuliskan kode sederhana di bawah ini, kita dapat menggunakan API Kaggle untuk mengunduh data ke dalam notebook kita. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8TpyI7H77z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c3d4c4e-7bf9-4859-c5ff-d632367430b1"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"dzelrahman\"\n",
        "os.environ['KAGGLE_KEY'] = \"22981b181745de2419d1ae63d77468e8\"\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chest-xray-pneumonia.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB4mqfJe_aWf",
        "colab_type": "text"
      },
      "source": [
        "Kemudian, file yang sudah diunduh harus diunzip terlebih dahulu karena file masih berupa format zip, dan pula ditentukan direktori khusus untuk set train, test, dan validation. Ditentukan pula direktori untuk dua kelas, normal dan pneumonia untuk masing-masing data train dan validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u17D7oq8SFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "local_zip = \"/content/chest-xray-pneumonia.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND5i1RXX-M13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/content/chest_xray'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb0AW8yK-WM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_normal_dir = os.path.join(train_dir, 'NORMAL')\n",
        "train_pneu_dir = os.path.join(train_dir, 'PNEUMONIA')\n",
        "validation_normal_dir = os.path.join(validation_dir, 'NORMAL')\n",
        "validation_pneu_dir = os.path.join(validation_dir, 'PNEUMONIA')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfMUttY9DU8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29ccb990-35ab-4970-e759-39400c7f4c6a"
      },
      "source": [
        "print(len(os.listdir(train_normal_dir)))\n",
        "print(len(os.listdir(train_pneu_dir)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1341\n",
            "3875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaFyVIQ4Dit5",
        "colab_type": "text"
      },
      "source": [
        "Ada sebanyak 1341 citra X-ray yang tergolong berparu-paru normal dan ada 3875 citra x-ray yang tergolong mengidap pneumonia, dimana jumlah gambar ini sudah mencukupi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jv3Yx0MDYdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJRTHz5mDdxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size=[224,224]\n",
        "model=tf.keras.applications.resnet50.ResNet50(input_shape=img_size + [3], weights='imagenet', include_top=False)\n",
        "model.trainable = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4VtbDUebMAE",
        "colab_type": "text"
      },
      "source": [
        "Lapisan akhir dari arsitektur adalah 'conv5_block3_out' dengan bentuk/shape sebesar (7,7,2048) yang akan digunakan kemudian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s354RRK3DgYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39042cc0-a471-4d0f-e50c-23fce311d4f3"
      },
      "source": [
        "last_layer = model.get_layer(\"conv5_block3_out\")\n",
        "print(\"last layer output shape: \", last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yha8Ul0IblGb",
        "colab_type": "text"
      },
      "source": [
        "Kita kemudian menentukan 2 lapisan terakhir, lapisan dense dengan 1024 jumlah nodes, dengan rasio dropout sebesar 20% untuk menanggulangi overfitting. Lapisan berikutnya adalah lapisan terakhir dengan node tunggal dan ditambah dengan aktivasi sigmoid (yang menghasilkan keluaran berupa 0 dan 1 untuk klasifikasi)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmQK9Us7Dlyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(1024, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.Dense(1,activation='sigmoid')(x)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJOHw8vEDoBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "amodel = Model(model.input,x)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MjgINiUeV1g",
        "colab_type": "text"
      },
      "source": [
        "Lapisan yang terdapat pada model kita, bernama amodel, dan bentuk beserta ukurannya dapat dilihat menggunakan fungsi summary()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqg3gN5pDqkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68a98707-c329-40e9-e57c-d9c24a0f7c26"
      },
      "source": [
        "amodel.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         102761472   flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 126,350,209\n",
            "Trainable params: 102,762,497\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fnoXFYlg2Tk",
        "colab_type": "text"
      },
      "source": [
        "Setelah melakukan fit terhadap model, model dicompile menggunakan RMSProp sebagai optimizer dan juga binary_crossentropy sebagai loss karena hasil akan berupa salah satu dari dua kelas prediksi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVwGE9OyDsh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "amodel.compile(optimizer = RMSprop(lr=0.0001),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB2BUekmhP8C",
        "colab_type": "text"
      },
      "source": [
        "Selanjutnya, kita menggunakan fungsi ImageDataGenerator pada Keras untuk memasukkan/mengimport gambar dan melakukan beberapa data augmentasi terhadap gambar tersebut, dan juga menuliskan beberapa argumen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGA4zO_4Du8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "047cc2ec-1263-4fbb-8ec4-b7f45367c04f"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                  rotation_range = 40,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   batch_size=20,\n",
        "                                                   class_mode = 'binary',\n",
        "                                                   target_size = (224,224))\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                       batch_size = 20,\n",
        "                                                       class_mode = 'binary',\n",
        "                                                       target_size = (224,224))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoj8yNNMjlWE",
        "colab_type": "text"
      },
      "source": [
        "Ada 5216 gambar untuk training dan 16 gambar untuk validation. Langkah terakhir yang dilakukan adalah melakukan running terhadap model sebanyak 10 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTzZCthvDxBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "de87c518-8bd7-462f-e657-7ab9bb036ced"
      },
      "source": [
        "history = amodel.fit(train_generator,\n",
        "                    validation_data = validation_generator,\n",
        "                    steps_per_epoch = 100,\n",
        "                    epochs = 10,\n",
        "                    validation_steps = 50,\n",
        "                    verbose = 2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 40s - loss: 0.8766 - accuracy: 0.6995 - val_loss: 0.6713 - val_accuracy: 0.5625\n",
            "Epoch 2/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.5579 - accuracy: 0.7340 - val_loss: 0.6691 - val_accuracy: 0.5625\n",
            "Epoch 3/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.5284 - accuracy: 0.7365 - val_loss: 1.1267 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.4807 - accuracy: 0.7685 - val_loss: 0.9095 - val_accuracy: 0.5625\n",
            "Epoch 5/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.4465 - accuracy: 0.7886 - val_loss: 1.0115 - val_accuracy: 0.5625\n",
            "Epoch 6/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 40s - loss: 0.4675 - accuracy: 0.7705 - val_loss: 0.8168 - val_accuracy: 0.5625\n",
            "Epoch 7/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.8150 - val_accuracy: 0.6250\n",
            "Epoch 8/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.4186 - accuracy: 0.7915 - val_loss: 0.5470 - val_accuracy: 0.6875\n",
            "Epoch 9/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.4212 - accuracy: 0.7955 - val_loss: 0.8042 - val_accuracy: 0.6250\n",
            "Epoch 10/10\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 - 39s - loss: 0.3977 - accuracy: 0.8105 - val_loss: 0.5555 - val_accuracy: 0.6875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HM61PQPSxUy",
        "colab_type": "text"
      },
      "source": [
        "Kita berhasil mendapatkan sekitar 81% akurasi setelah 10 epochs. Akurasi validasi adalah sekitar 62%. Arsitektur lain seperti VGG16 atau VGG19 dapat pula digunakan dan dapat meningkatkan akurasi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xQ4gcDmHJL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "fdee97e9-0bcf-4267-9e72-5cf7fbdb4dd7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjX5Jb-1TGX4",
        "colab_type": "text"
      },
      "source": [
        "Akurasi training nampak meningkat secara konsisten, namun akurasi validasi nampak naik dan turun, meskipun secara umum meningkat. Ini bisa jadi merupakan salah satu tanda terjadinya overfit, namun bukan overfit yang parah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWb6JF_3ToXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}